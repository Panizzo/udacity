{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P3: Limpando os dados do OpenStreetMap\n",
    "\n",
    "Daniel Senna Panizzo - Udacity - Área do mapa: Brasília, DF, Brasil \n",
    "\n",
    "#### Resumo\n",
    "\n",
    "O presente projeto tem o intuito de verificar o aprendizado do autor nas lições de limpeza de dados do Nanodegree em Análise de Dados do Udacity. Utilizando os [dados da área de Brasília, DF, Brasil](https://mapzen.com/data/metro-extracts/metro/brasilia_brazil/) do OpenStreetMap, passaremos pelo processo de auditoria, carga e análise dos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fase 01: Aquisição dos dados\n",
    "\n",
    "Para a execução dos testes deste projeto foi utilizada apenas o área do bairro \"Asa Norte\" em Brasília, escolha feita por ser meu atual local de moradia. A extração desta amostra de dados foi realizada pela ferramenta de seleção manual do OpenStreetMap utilizando os seguintes parâmetros de latitude e longitude: -15.7300, -47.8480, -15.7940, -47.9080 (inseridos no sentido horário).\n",
    "\n",
    "Abaixo exploraremos quais elementos XML estão disponíveis na nossa extração de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bounds': 1,\n",
       " 'member': 6270,\n",
       " 'nd': 614950,\n",
       " 'node': 469773,\n",
       " 'osm': 1,\n",
       " 'relation': 897,\n",
       " 'tag': 217563,\n",
       " 'way': 94443}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##################################\n",
    "#       BIBLIOTECAS PYTHON       #\n",
    "##################################\n",
    "import csv\n",
    "import codecs\n",
    "import pprint\n",
    "import re\n",
    "import xml.etree.cElementTree as ET\n",
    "from collections import defaultdict\n",
    "import cerberus\n",
    "import schema\n",
    "import json\n",
    "\n",
    "# Caminho do arquivo de amostra de dados do OpenStreetMap\n",
    "# OSM_PATH = \"brasilia_sample.osm\"\n",
    "# Caminho do arquivo completo de dados do OpenStreetMap\n",
    "OSM_PATH = \"brasilia_brazil.osm\" \n",
    "\n",
    "def count_tags(filename):\n",
    "    \"\"\"\n",
    "    Funcao para identificar e contar a quantidade de tags em um arquivo XML.\n",
    "    \n",
    "    Args:\n",
    "        filename (str): Caminho e nome do arquivo XML.\n",
    "                        Ex.: \"C:\\Dados\\Arquivo.xml\" \n",
    "    Returns:\n",
    "        dic: Key   = Tags identificadas no arquivo XML\n",
    "             Value = Quantidade de vezes que a tag apareceu no arquivo XML.\n",
    "             Ex.: {\"nome_tag_01\": 10, \"nome_tag_02\": 2}\n",
    "    \"\"\"\n",
    "    tags = {}\n",
    "    for event, elem in ET.iterparse(filename):\n",
    "        if elem.tag in tags:\n",
    "            tags[elem.tag] += 1\n",
    "        else:\n",
    "            tags[elem.tag] = 1\n",
    "    return tags\n",
    "\n",
    "count_tags(OSM_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "O resultado condiz a descrição do conteúdo de um arquivo OSM, conforme a [Wiki do OpenStreetMaps](https://wiki.openstreetmap.org/wiki/OSM_XML).\n",
    "\n",
    "ELEMENTO | DESCRIÇÃO\n",
    "---------|----------\n",
    "OSM      | Informa a versão da API, a ferramenta que gerou a extração dos dados e informações de licença.\n",
    "BOUNDS   | Informa as latitudes e longitudes dos pontos máximos e mínimos da área em que os dados estão contidos.\n",
    "NODE     | Um bloco de *nodes* contendo a localização (latidude e longitude) no sistema de referenciamento WGS84. Cada *node* representa um ponto específico na supercie da Terra. \n",
    "WAY      | Um bloco de *ways* referenciando os *nodes* (*nd*) de cada *way*. Um *way* pode ser utilizado para representar elementos lineares como ruas ou rios. Também pode ser utilizado ou para representar os limites de uma área, como um parque ou um prédio. \n",
    "RELATION | Um bloco de *relations* referenciando cada um dos *members* de cada *relation*. *Relations* são estruturas de dados de multi-propósito utilizadas para representar relações entre seus elementos (*nodes*, *ways* ou outras *relations*).\n",
    "TAG      | Todos os tipos de elementos (*nodes*, *ways* e *relations*) podem ter *tags*. *Tags* descrevem o elemento ao qual estão ligados. A descrição é feita no formato chave-valor (*key-value*).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fase 02: Preparação dos dados\n",
    "\n",
    "Continuando com a análise dos dados que foram inseridos pelos colaboradores do OSM, vamos verificar se no nosso arquivo existe algum elemento *tag* com nome problemático, ou seja, que contenha caracteres incomuns como %, #, $, @, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lower': 206850, 'lower_colon': 10178, 'other': 535, 'problemchars': 0}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expressoes Regulares (Regular Expressions):\n",
    "# Para identificar nomes com todos os caracteres minusculos\n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "\n",
    "# Para identificar nomes com todos os caracteres minusculos e dois pontos no meio\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "\n",
    "# Para identificar nomes que contenham qualquer caractere problematico\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "def key_type(element, keys):\n",
    "    \"\"\"\n",
    "    Funcao para classificar o nome da key de um elemento tag entre:\n",
    "    - lower:       nomes em caixa baixa\n",
    "    - lower_colon: nomes em caixa baixa com dois pontos no meio\n",
    "    - problemchar: nomes com caracteres problematicos\n",
    "    - other:       outro tipo de nome\n",
    "    \n",
    "    Args:\n",
    "        element (cursor): Cursor contendo o elemento XML em analise\n",
    "    Returns:\n",
    "        dic: Dicionario contendo a quantidade de nomes em cada classificacao.\n",
    "    \"\"\"\n",
    "    if element.tag == \"tag\":\n",
    "        key = element.attrib['k']\n",
    "        if re.search(lower, key):\n",
    "            keys['lower'] += 1\n",
    "        elif re.search(lower_colon, key):\n",
    "            keys['lower_colon'] += 1\n",
    "        elif re.search(problemchars, key):\n",
    "            keys['problemchars'] += 1\n",
    "        else:\n",
    "            keys['other'] += 1\n",
    "\n",
    "    return keys\n",
    "\n",
    "def process_class_keys(filename):\n",
    "    \"\"\"\n",
    "    Funcao para classificar e contar as keys do elemento tag do arquivo OSM do OpenStreetMap.\n",
    "    \n",
    "    Args:\n",
    "        filename (str): Caminho e nome do arquivo XML.\n",
    "                        Ex.: \"C:\\Dados\\Arquivo.xml\"\n",
    "    Returns:\n",
    "        dic: Dicionario contendo a quantidade de nomes em cada classificacao.\n",
    "             Ex.: {\"lower\": 100, \"lower_colon\": 50, \"problemchars\": 10, \"other\": 10}\n",
    "    \"\"\"\n",
    "    keys = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        keys = key_type(element, keys)\n",
    "\n",
    "    return keys\n",
    "\n",
    "process_class_keys(OSM_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Dentre as *keys* de cada *tag*, nenhum nome foi classificado com caracteres problemáticos. Portanto, podemos seguir com a exploração dos valores dos campos que nos interessam.\n",
    "\n",
    "O foco do nosso projeto é auditar, principalmente, o endereço fornecido pelos colaboradores do Open Street Maps. A seguir, daremos uma olhada no campo \"addr:street\" para verficarmos como os usuários estão preenchendo este campo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'EQ 15/26 \\xc1REA COMUNAL 01', 1),\n",
       " ('Quadra 14 Conjunto A5', 1),\n",
       " (u'Condom\\xednio Ch\\xe1caras Itaip\\xfa, Ch. 58', 2),\n",
       " ('SIG Quadra 06', 1),\n",
       " (u'QN 09 \\xc1rea Central 04', 1),\n",
       " (u'QL 32 SEDB - A.E. 01 - lago sul - Bras\\xedlia', 1),\n",
       " ('CSG 09 Lote 10', 1),\n",
       " ('Avenida Dois', 1),\n",
       " ('EQS 514-515', 1),\n",
       " ('CLN 216 BL. C', 1)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_key_name(element, key_name):\n",
    "    \"\"\"\n",
    "    Funcao para verificar se a tag e referente ao atributo desejado.\n",
    "    \n",
    "    Args:\n",
    "        element (cursor): Cursor contendo o elemento XML em analise.\n",
    "        key_name (str): Nome do atributo desejado.\n",
    "    Returns:\n",
    "        bool: Verdadeiro se for uma tag do atributo desejado, caso contrario, falso.\n",
    "    \"\"\"\n",
    "    return (element.attrib['k'] == key_name)\n",
    "\n",
    "def count_key_names(key_names, key_name):\n",
    "    \"\"\"\n",
    "    Funcao para identificar e contar a quantidade de diferentes endereços.\n",
    "    \n",
    "    Args:\n",
    "        key_names (dic): Dicionario contendo a quantidade de cada endereço.\n",
    "        key_name (str): Nome do endereço verificado.\n",
    "    \"\"\"\n",
    "    if key_name in key_names:\n",
    "        key_names[key_name] += 1\n",
    "    else:\n",
    "        key_names[key_name] = 1\n",
    "\n",
    "def process_key(filename, key_name):\n",
    "    \"\"\"\n",
    "    Funcao que verifica todas as tags de endereco de um arquivo OSM e lista\n",
    "    todos os diferentes enderecos e a quantidade de vezes em que aparece no \n",
    "    arquivo em um dicionario.\n",
    "    \n",
    "    Args:\n",
    "        filename (str): Caminho e nome do arquivo XML.\n",
    "                        Ex.: \"C:\\Dados\\Arquivo.xml\"   \n",
    "    Returns:\n",
    "        dic: Dicionario contendo a quantidade vezes que os endereços aparecem no arquivo.\n",
    "    \"\"\"\n",
    "    osm_file = open(filename, \"r\")\n",
    "    street_names = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_key_name(tag, key_name):\n",
    "                    count_key_names(street_names, tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    return street_names\n",
    "\n",
    "# Amostra dos dados das tags de endereco\n",
    "process_key(OSM_PATH, 'addr:street').items()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como morador de Brasília posso dizer que a maior parte dos endereços me é familiar. No entanto, a grande maioria dos endereços estão abreviados. É comum em Brasília comunicarmos os endereços utilizando apenas as siglas, mas cada uma delas possui um significado.\n",
    "\n",
    "Podemos encontrar até nomes que tentam conciliar a sigla com o nome completo, como em:\n",
    "\n",
    "- SCEN Trecho 1 Setor de Clubes Norte\n",
    "\n",
    "Ainda assim, o nome completo fornecido está errado, já que SCEN é referente a \"Setor de Clubes ESPORTIVOS Norte\".\n",
    "\n",
    "Visto que entre moradores da cidade é normal o uso de siglas, ao auditarmos os dados, manteremos a sigla ao final do nome completo do endereço.\n",
    "\n",
    "A seguir daremos uma olhada no campo \"addr:postcode\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('70852520', 1),\n",
       " ('70680-900', 1),\n",
       " ('70342-060', 1),\n",
       " ('70236-150', 1),\n",
       " ('70236-010', 1),\n",
       " ('71570-050', 2),\n",
       " ('70640-009', 1),\n",
       " ('70775-010', 1),\n",
       " ('71060-250', 1),\n",
       " ('70.687-230', 1)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Amostra de dados das tags de codigo postal\n",
    "process_key(OSM_PATH, 'addr:postcode').items()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A boa notícia é que os códigos postais (CEPs) parecem estar bem documentados. Assim, podemos aplicar alguns critérios de auditoria de dados. \n",
    "\n",
    "Ao verificar a **validade**, podemos observar:\n",
    "- Se o CEP inicia com o número 7, padrão do Distrito Federal;\n",
    "- Se o CEP possui 8 digitos numéricos; \n",
    "\n",
    "Para verificar a **precisão** e **plenitude** dos CEPs, poderímos utilizar o banco de dados de logradouros dos Correios como referência. Infelizmente este conjunto de dados não é disponibilizado gratuitamente para uso. \n",
    "\n",
    "Ao aplicar um tratamento de dados nos CEPs e padronizá-los para terem apenas digitos, podemos testar sua **consistência** ao comparar se diferentes latitudes e longitudes possuem os mesmos CEPs. Podemos, também, considerar que os CEPs estão **uniformes**, visto que não há outro tipo de código postal dentro do território brasileiro.\n",
    "\n",
    "Como estratégia de tratamento dos dados, como as difereças entre os CEPs residem principalmente na maneira como foram escritas, para padronizá-las iremos retirar todos os outros caracteres que não sejam números. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando como base a lista de siglas de Brasília disponível neste [blog](http://siglasbsb.alanmol.com.br/p/siglas.html), seguiremos para o mapeamento das siglas com seus respectivos nomes e padronização da escrita do código postal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Expressoes Regulares (Regular Expressions):\n",
    "# Para identificar a primeira palavra completa do endereço, seguida ou não de ponto\n",
    "street_abbr_re = re.compile(r'^\\b\\S+\\.?', re.IGNORECASE)\n",
    "# Para identificar caracteres não numéricos\n",
    "postcode_clean_re = re.compile(r'\\D')\n",
    "\n",
    "# Lista de siglas esperadas de serem encontradas nos enderecos de Brasilia\n",
    "expected = [\"ADE\",\"AE\",\"AEB\",\"AEMN\",\"AENW\",\"AOS\",\"APO\",\"ARIE\",\"AVPR\",\"BOT\",\"BSB\",\"CA\",\"CADF\",\"CCSW\",\"CEN\"\n",
    "           ,\"CES\",\"CE-UNB\",\"CL\",\"CLN\",\"CLRN\",\"CLS\",\"CLSW\",\"CRS\",\"EMI\",\"EMO\",\"EPAA\",\"EPAC\",\"EPAR\",\"EPCA\"    \n",
    "           ,\"EPCL\",\"EPCT\",\"EPCV\",\"EPDB\",\"EPGU\",\"EPIA\",\"EPIB\",\"EPIG\",\"EPIP\",\"EPJK\",\"EPNA\",\"EPNB\",\"EPPN\"\n",
    "           ,\"EPPR\",\"EPTG\",\"EPTM\",\"EPTT\",\"EPUB\",\"EPVB\",\"EPVL\",\"EPVP\",\"EQN\",\"EQS\",\"ERL\",\"ERN\",\"ERS\",\"ERW\"\n",
    "           ,\"ESAF\",\"ETO\",\"ML\",\"PCH\",\"PFB\",\"PFR\",\"PMU\",\"PQEAT\",\"PQEB\",\"PQEN\",\"PQNB\",\"PTP\",\"QELC\",\"QI\"      \n",
    "           ,\"QL\",\"QMSW\",\"QRSW\",\"RER-IBGE\",\"SAAN\",\"SAFN\",\"SAFS\",\"SAI/SO\",\"SAIN\",\"SAIS\",\"SAM\",\"SAN\",\"SAUN\"\n",
    "           ,\"SAS\",\"SAUS\",\"SBN\",\"SBS\",\"SCEN\",\"SCES\",\"SCIA\",\"SCLRN\",\"SCN\",\"SCS\",\"SCRN\",\"SCRS\",\"SCTN\",\"SCTS\",\"SDC\",\"SDN\"\n",
    "           ,\"SDS\",\"SEDB\",\"SEN\",\"SEN\",\"SEPN\",\"SEPS\",\"SES\",\"SEUPS\",\"SFA\",\"SGA\",\"SGAN\",\"SGAS\",\"SGCV\",\"SGMN\"\n",
    "           ,\"SGO\",\"SGON\",\"SHA\",\"SHB\",\"SHCES\",\"SHCGN\",\"SHCGS\",\"SHCN\",\"SHCNW\",\"SHCS\",\"SHCSW\",\"SHEP\",\"SHIGS\"\n",
    "           ,\"SHIN\",\"SHIP\",\"SHIS\",\"SHLN\",\"SHLS\",\"SHLSW\",\"SHMA\",\"SHN\",\"SHS\",\"SHTN\",\"SHTO\",\"SHTQ\",\"SHTS\"\n",
    "           ,\"SIA\",\"SIBS\",\"SIG\",\"SIT\",\"SMA\",\"SMAN\",\"SMAS\",\"SMC\",\"SMDB\",\"SMHN\",\"SMHS\",\"SMIN\",\"SMLN\",\"SMPW\"\n",
    "           ,\"SMU\",\"SOF\",\"SPMN\",\"SPO\",\"SPP\",\"SPVP\",\"SQN\",\"SQNW\",\"SQS\",\"SQSW\",\"SRES\",\"SRIA\",\"SRPN\",\"SRPS\"  \n",
    "           ,\"SRTVN\",\"SRTVS\",\"STN\",\"STRC\",\"STS\",\"UNB\",\"VPLA\",\"ZC\",\"ZCA\",\"ZE\",\"ZFN\",\"ZI\",\"ZR\",\"ZV\"]\n",
    "\n",
    "# Mapeamento das siglas e seus respectivos nomes completos\n",
    "mapping = {\"ADE\" : \"Área de Desenvolvimento Econômico (ADE)\"\n",
    "        ,\"AE\" : \"Área Especial (AE)\"\n",
    "        ,\"AEB\" : \"Aeroporto de Brasília (AeB)\"\n",
    "        ,\"AEMN\" : \"Área de Expansão dos Ministérios Norte (AEMN)\" \n",
    "        ,\"AENW\" : \"Área Especial Noroeste (AENW)\"\n",
    "        ,\"AOS\" : \"Área Octogonal Sul (AOS)\" \n",
    "        ,\"APO\" : \"Academia de Polícia (APO)\"\n",
    "        ,\"ARIE\" : \"Área de Relevante Interesse Ecológico (ARIE)\"\n",
    "        ,\"AVPR\" : \"Área Verde de Proteção e Reserva (AVPR)\"\n",
    "        ,\"BOT\" : \"Jardim Botânico (BOT)\"\n",
    "        ,\"BSB\" : \"Brasília (BSB)\"\n",
    "        ,\"CA\" : \"Centro de Atividades (CA)\"\n",
    "        ,\"CADF\" : \"Centro Administrativo do Distrito Federal (CADF)\" \n",
    "        ,\"CCSW\" : \"Centro Comercial Sudoeste (CCSW)\"\n",
    "        ,\"CEN\" : \"Cemitério Norte (CEN)\"\n",
    "        ,\"CES\" : \"Cemitério Sul (CES)\"\n",
    "        ,\"CE-UNB\" : \"Campus Experimental da UnB (CE-UnB)\"\n",
    "        ,\"CL\" : \"Comércio Local (CL)\"\n",
    "        ,\"CLN\" : \"Comércio Local Norte (CLN)\"\n",
    "        ,\"CLRN\" : \"Comércio Local Residencial Norte (CLRN)\"\n",
    "        ,\"CLS\" : \"Comércio Local Sul (CLS)\"\n",
    "        ,\"CLSW\" : \"Comércio Local Sudoeste (CLSW)\"\n",
    "        ,\"CRS\" : \"Comércio Residencial Sul (CRS)\"\n",
    "        ,\"EMI\" : \"Esplanada dos Ministérios (EMI)\"\n",
    "        ,\"EMO\" : \"Eixo Monumental (EMO)\"\n",
    "        ,\"EPAA\" : \"Estrada Parque Armazenamento e Abastecimento (EPAA)\"\n",
    "        ,\"EPAC\" : \"Estrada Parque Acampamento (EPAC)\"\n",
    "        ,\"EPAR\" : \"Estrada Parque Aeroporto (EPAR)\"\n",
    "        ,\"EPCA\" : \"Estrada Parque Centro de Atividades (EPCA)\"\n",
    "        ,\"EPCL\" : \"Estrada Parque Ceilândia (EPCL)\"\n",
    "        ,\"EPCT\" : \"Estrada Parque Contorno (EPCT)\"\n",
    "        ,\"EPCV\" : \"Estrada Parque Cabeça do Veado (EPCV)\"\n",
    "        ,\"EPDB\" : \"Estrada Parque Dom Bosco (EPDB)\"\n",
    "        ,\"EPGU\" : \"Estrada Parque Guará (EPGU)\"\n",
    "        ,\"EPIA\" : \"Estrada Parque Indústria e Abastecimento (EPIA)\"\n",
    "        ,\"EPIB\" : \"Estrada Parque Interbairros (EPIB)\"\n",
    "        ,\"EPIG\" : \"Estrada Parque Indústrias Gráficas (EPIG)\"\n",
    "        ,\"EPIP\" : \"Estrada Parque Ipê (EPIP)\"\n",
    "        ,\"EPJK\" : \"Estrada Parque Juscelino Kubitschek (EPJK)\"\n",
    "        ,\"EPNA\" : \"Estrada Parque das Nações (EPNA)\"\n",
    "        ,\"EPNB\" : \"Estrada Parque Núcleo Bandeirante (EPNB)\"\n",
    "        ,\"EPPN\" : \"Estrada Parque Península Norte (EPPN)\"\n",
    "        ,\"EPPR\" : \"Estrada Parque Paranoá (EPPR)\"\n",
    "        ,\"EPTG\" : \"Estrada Parque Taguatinga (EPTG)\"\n",
    "        ,\"EPTM\" : \"Estrada Parque Tamanduá (EPTM)\"\n",
    "        ,\"EPTT\" : \"Estrada Parque Torto (EPTT)\"\n",
    "        ,\"EPUB\" : \"Estrada Parque Universidade de Brasília (EPUB)\"\n",
    "        ,\"EPVB\" : \"Estrada Parque Vargem Bonita (EPVB)\"\n",
    "        ,\"EPVL\" : \"Estrada Parque Vale (EPVL)\"\n",
    "        ,\"EPVP\" : \"Estrada Parque Vicente Pires (EPVP)\"\n",
    "        ,\"EQN\" : \"Entrequadra Norte (EQN)\"\n",
    "        ,\"EQS\" : \"Entrequadra Sul (EQS)\"\n",
    "        ,\"ERL\" : \"Eixo Rodoviário Leste (ERL)\"\n",
    "        ,\"ERN\" : \"Eixo Rodoviário Norte (ERN)\"\n",
    "        ,\"ERS\" : \"Eixo Rodoviário Sul (ERS)\"\n",
    "        ,\"ERW\" : \"Eixo Rodoviário Oeste (ERW)\"\n",
    "        ,\"ESAF\" : \"Escola de Administração Fazendária (ESAF)\"\n",
    "        ,\"ETO\" : \"Esplanada da Torre (ETO)\"\n",
    "        ,\"ML\" : \"Mansões do Lago (ML)\"\n",
    "        ,\"PCH\" : \"Polígono de Captação Hídrica (PCH)\"\n",
    "        ,\"PFB\" : \"Parque Ferroviário de Brasília (PFB)\"\n",
    "        ,\"PFR\" : \"Plataforma Rodoviária (PFR)\"\n",
    "        ,\"PMU\" : \"Praça Municipal (PMU)\"\n",
    "        ,\"PQEAT\" : \"Parque de Exposição Agropecuária do Torto (PqEAT)\"\n",
    "        ,\"PQEB\" : \"Parque Estação Biológica (PqEB)\"\n",
    "        ,\"PQEN\" : \"Parque Ecológico Norte (PqEN)\"\n",
    "        ,\"PQNB\" : \"Parque Nacional de Brasília (PqNB)\"\n",
    "        ,\"PTP\" : \"Praça dos Três Poderes (PTP)\"\n",
    "        ,\"QELC\" : \"Quadras Econômicas Lúcio Costa (QELC)\"\n",
    "        ,\"QI\" : \"Quadra Interna (QI)\"\n",
    "        ,\"QL\" : \"Quadra do Lago (QL)\"\n",
    "        ,\"QMSW\" : \"Quadra Mista Sudoeste (QMSW)\"\n",
    "        ,\"QRSW\" : \"Quadra Residencial Sudoeste (QRSW)\"\n",
    "        ,\"RER-IBGE\" : \"Reserva Ecológica do Roncador - IBGE (RER-IBGE)\"\n",
    "        ,\"SAAN\" : \"Setor de Armazenagem e Abastecimento Norte (SAAN)\"\n",
    "        ,\"SAFN\" : \"Setor de Administração Federal Norte (SAFN)\"\n",
    "        ,\"SAFS\" : \"Setor de Administração Federal Sul (SAFS)\"\n",
    "        ,\"SAI/SO\" : \"Setor de Áreas Isoladas Sudoeste (SAI/SO)\"\n",
    "        ,\"SAIN\" : \"Setor de Áreas Isoladas Norte (SAIN)\"\n",
    "        ,\"SAIS\" : \"Setor de Áreas Isoladas Sul (SAIS)\"\n",
    "        ,\"SAM\" : \"Setor de Administração Municipal (SAM)\"\n",
    "        ,\"SAN\" : \"Setor de Autarquias Norte (SAN)\"\n",
    "        ,\"SAUN\" : \"Setor de Autarquias Norte (SAUN)\"\n",
    "        ,\"SAS\" : \"Setor de Autarquias Sul (SAS)\"\n",
    "        ,\"SAUS\" : \"Setor de Autarquias Sul (SAUS)\"\n",
    "        ,\"SBN\" : \"Setor Bancário Norte (SBN)\"\n",
    "        ,\"SBS\" : \"Setor Bancário Sul (SBS)\"\n",
    "        ,\"SCEN\" : \"Setor de Clubes Esportivos Norte (SCEN)\"\n",
    "        ,\"SCES\" : \"Setor de Clubes Esportivos Sul (SCES)\"\n",
    "        ,\"SCIA\" : \"Setor Complementar de Indústria e Abastecimento (SCIA)\"\n",
    "        ,\"SCLRN\" : \"Setor Comercial Local Residencial Norte (SCLRN)\"\n",
    "        ,\"SCN\" : \"Setor Comercial Norte (SCN)\"\n",
    "        ,\"SCS\" : \"Setor Comercial Sul (SCS)\"\n",
    "        ,\"SCRN\": \"Setor Comercial Residencial Norte (SCRN)\"\n",
    "        ,\"SCRS\": \"Setor Comercial Residencial Sul (SCRS)\"\n",
    "        ,\"SCTN\" : \"Setor Cultural Norte (SCTN)\"\n",
    "        ,\"SCTS\" : \"Setor Cultural Sul (SCTS)\"\n",
    "        ,\"SDC\" : \"Setor de Divulgação Cultural (SDC)\"\n",
    "        ,\"SDN\" : \"Setor de Diversões Norte (SDN)\"\n",
    "        ,\"SDS\" : \"Setor de Diversões Sul (SDS)\"\n",
    "        ,\"SEDB\" : \"Setor Hermida Dom Bosco (SEDB)\"\n",
    "        ,\"SEN\" : \"Setor de Embaixadas Norte (SEN)\"\n",
    "        ,\"SEPN\" : \"Setor de Edifícios Públicos Norte (SEPN)\"\n",
    "        ,\"SEPS\" : \"Setor de Edifícios Públicos Sul (SEPS)\"\n",
    "        ,\"SES\" : \"Setor de Embaixadas Sul (SES)\"\n",
    "        ,\"SEUPS\" : \"Setor de Edifícios e Utilidades Públicas Sul (SEUPS)\"\n",
    "        ,\"SFA\" : \"Zona Funcional-Administrativa (SFA)\"\n",
    "        ,\"SGA\" : \"Setor de Grandes Áreas (SGA)\"\n",
    "        ,\"SGAN\" : \"Setor de Grandes Áreas Norte (SGAN)\"\n",
    "        ,\"SGAS\" : \"Setor de Grandes Áreas Sul (SGAS)\"\n",
    "        ,\"SGCV\" : \"Setor de Garagens e Concessionárias de Veículos (SGCV)\"\n",
    "        ,\"SGMN\" : \"Setor de Garagens dos Ministérios Norte (SGMN)\"\n",
    "        ,\"SGO\" : \"Setor de Garagens Oficiais (SGO)\" \n",
    "        ,\"SGON\" : \"Setor de Garagens e Oficinas Norte (SGON)\"\n",
    "        ,\"SHA\" : \"Setor Habitacional Arniqueiras (SHA)\"\n",
    "        ,\"SHB\" : \"Setor Habitacional Buritis (SHB)\"\n",
    "        ,\"SHCES\" : \"Setor de Habitações Coletivas Econômicas Sul (SHCES)\"\n",
    "        ,\"SHCGN\" : \"Setor Habitacional de Casas Geminadas Norte (SHCGN)\"\n",
    "        ,\"SHCGS\" : \"Setor Habitacional de Casas Geminadas Sul (SHCGS)\"\n",
    "        ,\"SHCN\" : \"Setor de Habitações Coletivas Norte (SHCN)\"\n",
    "        ,\"SHCNW\" : \"Setor de Habitações Coletivas Noroeste (SHCNW)\"\n",
    "        ,\"SHCS\" : \"Setor de Habitações Coletivas Sul (SHCS)\"\n",
    "        ,\"SHCSW\" : \"Setor de Habitações Coletivas Sudoeste (SHCSW)\"\n",
    "        ,\"SHEP\" : \"Setor Habitacional Estrada Parque (SHEP)\" \n",
    "        ,\"SHIGS\" : \"Setor de Habitações Individuais Geminadas Sul (SHIGS)\"\n",
    "        ,\"SHIN\" : \"Setor de Habitações Individuais Norte (SHIN)\"\n",
    "        ,\"SHIP\" : \"Setor Hípico (SHIP)\"\n",
    "        ,\"SHIS\" : \"Setor de Habitações Individuais Sul (SHIS)\"\n",
    "        ,\"SHLN\" : \"Setor Hospitalar Local Norte (SHLN)\"\n",
    "        ,\"SHLS\" : \"Setor Hospitalar Local Sul (SHLS)\"\n",
    "        ,\"SHLSW\" : \"Setor Hospitalar Local Sudoeste (SHLSW)\"\n",
    "        ,\"SHMA\" : \"Setor Habitacional Jardins Mangueiral (SHMA)\"\n",
    "        ,\"SHN\" : \"Setor Hoteleiro Norte (SHN)\"\n",
    "        ,\"SHS\" : \"Setor Hoteleiro Sul (SHS)\"\n",
    "        ,\"SHTN\" : \"Setor de Hotéis e Turismo Norte (SHTN)\"\n",
    "        ,\"SHTO\" : \"Setor Habitacional Tororó (SHTo)\"\n",
    "        ,\"SHTQ\" : \"Setor Habitacional Taquari (SHTQ)\"\n",
    "        ,\"SHTS\" : \"Setor de Hotéis e Turismo Sul (SHTS)\"\n",
    "        ,\"SIA\" : \"Setor de Indústria e Abastecimento (SIA)\"\n",
    "        ,\"SIBS\" : \"Setor de Indústrias Bernardo Sayão (SIBS)\"\n",
    "        ,\"SIG\" : \"Setor de Indústrias Gráficas (SIG)\"\n",
    "        ,\"SIT\" : \"Setor Invernada do Torto (SIT)\"\n",
    "        ,\"SMA\" : \"Setor de Múltiplas Atividades do Gama (SMA)\"\n",
    "        ,\"SMAN\" : \"Setor de Múltiplas Atividades Norte (SMAN)\"\n",
    "        ,\"SMAS\" : \"Setor de Múltiplas Atividades Sul (SMAS)\"\n",
    "        ,\"SMC\" : \"Setor Militar Complementar (SMC)\"\n",
    "        ,\"SMDB\" : \"Setor de Mansões Dom Bosco (SMDB)\"\n",
    "        ,\"SMHN\" : \"Setor Médico Hospitalar Norte (SMHN)\"\n",
    "        ,\"SMHS\" : \"Setor Médico Hospitalar Sul (SMHS)\"\n",
    "        ,\"SMIN\" : \"Setor de Mansões Isoladas Norte (SMIN)\"\n",
    "        ,\"SMLN\" : \"Setor de Mansões Lago Norte (SMLN)\"\n",
    "        ,\"SMPW\" : \"Setor de Mansões Park Way (SMPW)\"\n",
    "        ,\"SMU\" : \"Setor Militar Urbano (SMU)\"\n",
    "        ,\"SOF\" : \"Setor de Oficinas (SOF)\"\n",
    "        ,\"SPMN\" : \"Setor de Postos e Moteis (SPMN)\"\n",
    "        ,\"SPO\" : \"Setor Policial (SPO)\"\n",
    "        ,\"SPP\" : \"Setor Palácio Presidencial (SPP)\"\n",
    "        ,\"SPVP\" : \"Setor de Preservação da Vila Planalto (SPVP)\"\n",
    "        ,\"SQN\" : \"Superquadra Norte (SQN)\"\n",
    "        ,\"SQNW\" : \"Superquadra Noroeste (SQNW)\"\n",
    "        ,\"SQS\" : \"Superquadra Sul (SQS)\"\n",
    "        ,\"SQSW\" : \"Superquadra Sudoeste (SQSW)\"\n",
    "        ,\"SRES\" : \"Setor de Residências Econômicas Sul (SRES)\"\n",
    "        ,\"SRIA\" : \"Setor Residencial Indústria e Abastecimento (SRIA)\"\n",
    "        ,\"SRPN\" : \"Setor de Recreação Pública Norte (SRPN)\"\n",
    "        ,\"SRPS\" : \"Setor de Recreação Pública Sul (SRPS)\"\n",
    "        ,\"SRTVN\" : \"Setor de Rádio e Televisão Norte (SRTVN)\"\n",
    "        ,\"SRTVS\" : \"Setor de Rádio e Televisão Sul (SRTVS)\"\n",
    "        ,\"STN\" : \"Setor Terminal Norte (STN)\"\n",
    "        ,\"STRC\" : \"Setor de Transporte Regional de Cargas (STRC)\"\n",
    "        ,\"STS\" : \"Setor Terminal Sul (STS)\"\n",
    "        ,\"UNB\" : \"Universidade de Brasília (UnB)\"\n",
    "        ,\"VPLA\" : \"Vila Planalto (VPLA)\"\n",
    "        ,\"ZC\" : \"Zona Central (ZC)\"\n",
    "        ,\"ZCA\" : \"Zona Cívico-Administrativa (ZCA)\"\n",
    "        ,\"ZE\" : \"Zona Especial (ZE)\"\n",
    "        ,\"ZFN\" : \"Zona Industrial (ZfN)\"\n",
    "        ,\"ZI\" : \"Zona Institucional (ZI)\"\n",
    "        ,\"ZR\" : \"Zona Residencial (ZR)\"\n",
    "        ,\"ZV\" : \"Zona Verde (ZV)\"}\n",
    "\n",
    "def update_name(name, mapping):\n",
    "    \"\"\"\n",
    "    Funcao que verifica se existe uma abreviacao conhecida no endereco e a substitui pelo\n",
    "    nome completo.\n",
    "    \n",
    "    Args:\n",
    "        name (str): Nome do endereco a ser verificado.\n",
    "        mapping (dic): Dicionario contendo a relacao de abreviacoes e seus respectivos nomes completos.\n",
    "    Returns:\n",
    "        str: Nome do endereco com a abreviacao substituida pelo nome completo.\n",
    "    \"\"\"\n",
    "    m = street_abbr_re.search(name)\n",
    "    if m:\n",
    "        street_abbr = m.group()\n",
    "        if street_abbr.upper() in expected:\n",
    "            name = re.sub(street_abbr_re\n",
    "                         ,mapping[street_abbr.upper()]\n",
    "                         ,name.encode('utf-8'))\n",
    "    return name\n",
    "\n",
    "def update_postcode(postcode):\n",
    "    \"\"\"\n",
    "    Funcao que limpa o codigo postal de caracteres não numéricos.\n",
    "    \n",
    "    Args:\n",
    "        postcode (str): Codigo postal a ser verificado.\n",
    "    Returns:\n",
    "        str: Codigo postal apenas com numeros.\n",
    "    \"\"\"\n",
    "    m = postcode_clean_re.search(postcode)\n",
    "    if m:\n",
    "        postcode_clean = m.group()\n",
    "        postcode = re.sub(postcode_clean_re, '', postcode)\n",
    "    return postcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Setor de Clubes Esportivos Norte (SCEN) Trecho 2'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Teste do tratamento do endereço\n",
    "update_name('Scen Trecho 2', mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'70767010'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Teste do tratamento do codigo postal\n",
    "update_postcode('70.767-0 1 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, com as funções de tratamento dos campos de endereço prontas, podemos preparar os dados para serem inseridos no banco de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Caminhos e nomes dos arquivos CSV \n",
    "# gerados após o tratamento dos dados\n",
    "NODES_PATH = \"nodes.csv\"\n",
    "NODE_TAGS_PATH = \"nodes_tags.csv\"\n",
    "WAYS_PATH = \"ways.csv\"\n",
    "WAY_NODES_PATH = \"ways_nodes.csv\"\n",
    "WAY_TAGS_PATH = \"ways_tags.csv\"\n",
    "\n",
    "# Modelo dos dados \n",
    "SCHEMA = schema.schema\n",
    "\n",
    "# Ordem das colunas do modelo SQL \n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']\n",
    "\n",
    "def update_value(key, value):\n",
    "    \"\"\"\n",
    "    Funcao que verifica se o campo e referente a um endereco ou codigo postal\n",
    "    e aplica o respectivo tratamento de dados quando necessario.\n",
    "    \n",
    "    Args:\n",
    "        key (str): Nome do campo em analise.\n",
    "        value (str): Valor do campo em analise.\n",
    "    Returns:\n",
    "        str: Valor do campo tratado em caso de endereco ou codigo postal.\n",
    "    \"\"\"\n",
    "    if key == 'street':\n",
    "        return update_name(value, mapping)\n",
    "    elif key == 'postcode':\n",
    "        return update_postcode(value)\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "def shape_element(element, node_attr_fields=NODE_FIELDS, way_attr_fields=WAY_FIELDS,\n",
    "                  problem_chars=problemchars, default_tag_type='regular'):\n",
    "    \"\"\"\n",
    "    Funcao para limpar e modelar os elementos node ou way do XML para um dicionario Python.\n",
    "    \n",
    "    Args:\n",
    "        element (cursor): Cursor contendo o elemento XML (tags node ou way) em analise.\n",
    "        node_attr_fields (array): Lista de campos de interesse da tag node.\n",
    "        way_attr_fields (array): Lista de campos de interesse da tag way.\n",
    "        problem_chars (regex): Funcao regex para identificacao de caracteres invalidos.\n",
    "        default_tag_type (str): Nome dado ao tipo de dado padrao.\n",
    "    Returns:\n",
    "        dic: Dicionario contendo a tag node ou way modelada e tratada.\n",
    "    \"\"\"\n",
    "\n",
    "    node_attribs = {}\n",
    "    way_attribs = {}\n",
    "    way_nodes = []\n",
    "    tags = []  # Handle secondary tags the same way for both node and way elements\n",
    "\n",
    "    # Se for uma tag NODE\n",
    "    if element.tag == 'node':\n",
    "\n",
    "        # Para cada atributo da tag NODE\n",
    "        for attr in element.attrib:\n",
    "            # Insere o valor do atributo da tag se o atributo\n",
    "            # estiver listado dentre as colunas do modelo SQL\n",
    "            if attr in node_attr_fields:\n",
    "                node_attribs[attr] = element.attrib[attr]\n",
    "\n",
    "        # Para cada subtag da tag NODE\n",
    "        for sub in element:\n",
    "            # Armazena o nome do atributo \"k\" (key) da subtag\n",
    "            key = sub.get(\"k\")\n",
    "            # Divide o nome da key da subtag em duas se houver dois pontos (:),\n",
    "            # ou seja, divide o nome da key se for uma subtag de endereco (addr)\n",
    "            keys = re.split(':',key,1)\n",
    "\n",
    "            # Se nao houver problemas no nome da key\n",
    "            if problem_chars.search(key) == None:\n",
    "                tag_dic = {}\n",
    "                # Armazena o id da subtag\n",
    "                tag_dic['id'] = node_attribs['id']\n",
    "                # Armazena a key da subtag, se for uma key de endereco insere e segunda parte da key\n",
    "                tag_dic['key'] = keys[0] if len(keys) == 1 else keys[1]\n",
    "                # Armazena o value da subtag, se for um value de endereco passa pelo tratamento dos dados\n",
    "                tag_dic['value'] = sub.get(\"v\") if len(keys) == 1 else update_value(keys[1], sub.get(\"v\"))\n",
    "                # Armazena o type da subtag, pode ser uma subtag regular ou subtag de endereco (addr)\n",
    "                tag_dic['type'] = default_tag_type if len(keys) == 1 else keys[0]\n",
    "\n",
    "                # Insere os attributos da subtag no dicionario\n",
    "                tags.append(tag_dic)\n",
    "\n",
    "        return {'node': node_attribs, 'node_tags': tags}\n",
    "\n",
    "    # Se for uma tag WAY\n",
    "    elif element.tag == 'way':\n",
    "\n",
    "        # Para cada atributo da tag WAY\n",
    "        for attr in element.attrib:\n",
    "            # Insere o valor do atributo da tag se o atributo\n",
    "            # estiver listado dentre as colunas do modelo SQL\n",
    "            if attr in way_attr_fields:\n",
    "                way_attribs[attr] = element.attrib[attr]\n",
    "\n",
    "        # Para cada subtag da tag WAY\n",
    "        for idx, sub in enumerate(element):\n",
    "\n",
    "            # Se for uma subtag TAG\n",
    "            if sub.tag == 'tag':\n",
    "                # Armazena o nome do atributo \"k\" (key) da subtag\n",
    "                key = sub.get(\"k\")\n",
    "                # Divide o nome da key da subtag em duas se houver dois pontos (:),\n",
    "                # ou seja, divide o nome da key se for uma subtag de endereco (addr)\n",
    "                keys = re.split(':',key,1)\n",
    "\n",
    "                if problem_chars.search(key) == None:\n",
    "                    tag_dic = {}\n",
    "                    # Armazena o id da subtag\n",
    "                    tag_dic['id'] = way_attribs['id']\n",
    "                    # Armazena a key da subtag, se for uma key de endereco insere e segunda parte da key\n",
    "                    tag_dic['key'] = keys[0] if len(keys) == 1 else keys[1]\n",
    "                    # Armazena o value da subtag, se for um value de endereco passa pelo tratamento dos dados\n",
    "                    tag_dic['value'] = sub.get(\"v\") if len(keys) == 1 else update_value(keys[1], sub.get(\"v\"))\n",
    "                    # Armazena o type da subtag, pode ser uma subtag regular ou subtag de endereco (addr)\n",
    "                    tag_dic['type'] = default_tag_type if len(keys) == 1 else keys[0]\n",
    "\n",
    "                    # Insere os attributos da subtag no dicionario\n",
    "                    tags.append(tag_dic)\n",
    "\n",
    "            # Se for uma subtag NODE\n",
    "            if sub.tag == 'nd':\n",
    "                tag_dic = {}\n",
    "                # Armazena o id da subtag\n",
    "                tag_dic['id'] = way_attribs['id']\n",
    "                # Armazena o id do NODE referenciado \n",
    "                tag_dic['node_id'] = sub.get(\"ref\")\n",
    "                # Armazena a posicao da subtag\n",
    "                tag_dic['position'] = idx\n",
    "\n",
    "                # Insere os attributos da subtag no dicionario\n",
    "                way_nodes.append(tag_dic)\n",
    "\n",
    "        return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}\n",
    "\n",
    "#========================================================#\n",
    "# ABAIXO ESTAO AS FUNCOES FORNECIDAS PELO ESTUDO DE CASO #\n",
    "#     PARA AUXILIO NA ESCRITA DOS DADOS PARA CSV         #\n",
    "#========================================================#\n",
    "\n",
    "# ================================================== #\n",
    "#               Helper Functions                     #\n",
    "# ================================================== #\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\"\"\"\n",
    "\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "\n",
    "def validate_element(element, validator, schema=SCHEMA):\n",
    "    \"\"\"Raise ValidationError if element does not match schema\"\"\"\n",
    "    if validator.validate(element, schema) is not True:\n",
    "        field, errors = next(validator.errors.iteritems())\n",
    "        message_string = \"\\nElement of type '{0}' has the following errors:\\n{1}\"\n",
    "        error_string = pprint.pformat(errors)\n",
    "\n",
    "        raise Exception(message_string.format(field, error_string))\n",
    "\n",
    "\n",
    "class UnicodeDictWriter(csv.DictWriter, object):\n",
    "    \"\"\"Extend csv.DictWriter to handle Unicode input\"\"\"\n",
    "\n",
    "    def writerow(self, row):\n",
    "        super(UnicodeDictWriter, self).writerow({\n",
    "            k: (v.encode('utf-8') if isinstance(v, unicode) else v) for k, v in row.iteritems()\n",
    "        })\n",
    "\n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)\n",
    "\n",
    "\n",
    "# ================================================== #\n",
    "#               Main Function                        #\n",
    "# ================================================== #\n",
    "def process_map(file_in, validate):\n",
    "    \"\"\"Iteratively process each XML element and write to csv(s)\"\"\"\n",
    "\n",
    "    with codecs.open(NODES_PATH, 'w') as nodes_file, \\\n",
    "         codecs.open(NODE_TAGS_PATH, 'w') as nodes_tags_file, \\\n",
    "         codecs.open(WAYS_PATH, 'w') as ways_file, \\\n",
    "         codecs.open(WAY_NODES_PATH, 'w') as way_nodes_file, \\\n",
    "         codecs.open(WAY_TAGS_PATH, 'w') as way_tags_file:\n",
    "\n",
    "        nodes_writer = UnicodeDictWriter(nodes_file, fieldnames=NODE_FIELDS, delimiter='|')\n",
    "        node_tags_writer = UnicodeDictWriter(nodes_tags_file, fieldnames=NODE_TAGS_FIELDS, delimiter='|')\n",
    "        ways_writer = UnicodeDictWriter(ways_file, fieldnames=WAY_FIELDS, delimiter='|')\n",
    "        way_nodes_writer = UnicodeDictWriter(way_nodes_file, fieldnames=WAY_NODES_FIELDS, delimiter='|')\n",
    "        way_tags_writer = UnicodeDictWriter(way_tags_file, fieldnames=WAY_TAGS_FIELDS, delimiter='|')\n",
    "\n",
    "        nodes_writer.writeheader()\n",
    "        node_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        way_nodes_writer.writeheader()\n",
    "        way_tags_writer.writeheader()\n",
    "\n",
    "        validator = cerberus.Validator()\n",
    "\n",
    "        for element in get_element(file_in, tags=('node', 'way')):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                if validate is True:\n",
    "                    validate_element(el, validator)\n",
    "\n",
    "                if element.tag == 'node':\n",
    "                    nodes_writer.writerow(el['node'])\n",
    "                    node_tags_writer.writerows(el['node_tags'])\n",
    "                elif element.tag == 'way':\n",
    "                    ways_writer.writerow(el['way'])\n",
    "                    way_nodes_writer.writerows(el['way_nodes'])\n",
    "                    way_tags_writer.writerows(el['way_tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_map(OSM_PATH, validate=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após a execução do código, os dados em XML do OpenStreetMap foram formatados em CSV nos seguintes arquivos:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "- nodes.csv........ 40.600 KB\n",
    "- nodes_tags.csv...  1.241 KB\n",
    "- ways.csv.........  6.020 KB\n",
    "- ways_nodes.csv... 15.157 KB\n",
    "- ways_tags.csv....  6.527 KB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em seguida modificaremos nossas funções para formatar os dados XML em JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lista dos campos de interesse sobre a criacao do elemento\n",
    "CREATED = [ \"version\", \"changeset\", \"timestamp\", \"user\", \"uid\"]\n",
    "\n",
    "def shape_element(element):\n",
    "    \"\"\"\n",
    "    Funcao para limpar e modelar os elementos node ou way do XML para um dicionario Python.\n",
    "    \n",
    "    Args:\n",
    "        element (cursor): Cursor contendo o elemento XML (tags node ou way) em analise.\n",
    "    Returns:\n",
    "        dic: Dicionario contendo a tag node ou way modelada e tratada.\n",
    "    \"\"\"\n",
    "    node = {}\n",
    "    \n",
    "    # Se for uma tag NODE ou WAY\n",
    "    if element.tag == \"node\" or element.tag == \"way\" :\n",
    "        \n",
    "        # Prepara as variaveis para insercao no documento (JSON)\n",
    "        node[\"type\"] = element.tag\n",
    "        node['created'] = {}\n",
    "        pos = []\n",
    "        node_refs = []\n",
    "        address = {}\n",
    "\n",
    "\n",
    "        # Para cada atributo na tag\n",
    "        for attr in element.attrib:\n",
    "            # Se o atributo estiver na lista de interesse dos campos de criacao\n",
    "            if attr in CREATED:\n",
    "                # Armazena o atributo dentro do dicionario 'created'\n",
    "                node['created'][attr] = element.attrib[attr]\n",
    "            # Se for um atributo de latidude ou longitude\n",
    "            elif attr in [\"lat\",\"lon\"]:\n",
    "                # Armazena o atributo dentro do array de posicao 'pos'\n",
    "                pos.append(float(element.attrib[attr]))\n",
    "            # Para os outros atributos\n",
    "            else:\n",
    "                # Armazena o valor e o nome do atributo\n",
    "                node[attr] = element.attrib[attr]\n",
    "\n",
    "        # Para cada subtag na tag NODE ou WAY\n",
    "        for sub in element:\n",
    "            # Se for uma subtag TAG\n",
    "            if sub.tag == 'tag':\n",
    "                # Armazena o nome do atributo \"k\" (key) da subtag\n",
    "                key = sub.get(\"k\")\n",
    "                # Divide o nome da key da subtag em duas se houver dois pontos (:),\n",
    "                # ou seja, divide o nome da key se for uma subtag de endereco (addr)\n",
    "                keys = re.split(':',key)\n",
    "\n",
    "                # Se nao houver problemas no nome da key\n",
    "                if problemchars.search(key) == None:\n",
    "                    # Se for um campo de endereco (addr)\n",
    "                    if keys[0] == 'addr' and len(keys) <= 2:\n",
    "                        # Armazena o endereco tratado no dicionario 'adress'\n",
    "                        address[keys[1]] = update_value(keys[1],sub.get(\"v\"))\n",
    "                    # Se for uma key com dois valores\n",
    "                    elif len(keys) == 2:\n",
    "                        # Cria um dicionario com o nome do primeiro valor\n",
    "                        node[keys[0]] = {}\n",
    "                        # Armazena o valor dentro do dicionario criado\n",
    "                        node[keys[0]][keys[1]] = sub.get(\"v\")\n",
    "                    # Para keys com apenas um valor\n",
    "                    else:\n",
    "                        # Armazena a chave e valor\n",
    "                        node[keys[0]] = sub.get(\"v\")\n",
    "\n",
    "            # Se for uma subtag NODE (nd)\n",
    "            if sub.tag == 'nd':\n",
    "                # Amazena a referencia ao node no array 'node_refs'\n",
    "                node_refs.append(sub.get(\"ref\"))\n",
    "\n",
    "        # Inclui os arrays no dicionario apenas se tiverem valores\n",
    "        if bool(node_refs):\n",
    "            node['node_refs'] = node_refs\n",
    "        if bool(address):\n",
    "            node['address'] = address\n",
    "        if bool(pos):\n",
    "            node['pos'] = pos\n",
    "\n",
    "        return node\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "#========================================================#\n",
    "# ABAIXO ESTAO AS FUNCOES FORNECIDAS PELO ESTUDO DE CASO #\n",
    "#     PARA AUXILIO NA ESCRITA DOS DADOS PARA JSON        #\n",
    "#========================================================#\n",
    "def process_map(file_in, pretty = False):\n",
    "    # You do not need to change this file\n",
    "    file_out = \"{0}.json\".format(file_in)\n",
    "    data = []\n",
    "    with codecs.open(file_out, \"w\") as fo:\n",
    "        for _, element in ET.iterparse(file_in):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                data.append(el)\n",
    "                if pretty:\n",
    "                    fo.write(json.dumps(el, indent=2)+\"\\n\")\n",
    "                else:\n",
    "                    fo.write(json.dumps(el) + \"\\n\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "process_map(OSM_PATH, True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após a execução do código, os dados em XML do OpenStreetMap foram formatados em JSON no seguinte arquivo:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "- brasilia_brazil.osm.json ..... 165.016 KB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Com os dados tratados, podemos inserí-los nos bancos de dados. Os dados em CSV serão inseridos no seguinte modelo de dados SQL:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "CREATE TABLE nodes (\n",
    "    id INTEGER PRIMARY KEY NOT NULL,\n",
    "    lat REAL,\n",
    "    lon REAL,\n",
    "    user TEXT,\n",
    "    uid INTEGER,\n",
    "    version INTEGER,\n",
    "    changeset INTEGER,\n",
    "    timestamp TEXT\n",
    ");\n",
    "\n",
    "CREATE TABLE nodes_tags (\n",
    "    id INTEGER,\n",
    "    key TEXT,\n",
    "    value TEXT,\n",
    "    type TEXT,\n",
    "    FOREIGN KEY (id) REFERENCES nodes(id)\n",
    ");\n",
    "\n",
    "CREATE TABLE ways (\n",
    "    id INTEGER PRIMARY KEY NOT NULL,\n",
    "    user TEXT,\n",
    "    uid INTEGER,\n",
    "    version TEXT,\n",
    "    changeset INTEGER,\n",
    "    timestamp TEXT\n",
    ");\n",
    "\n",
    "CREATE TABLE ways_tags (\n",
    "    id INTEGER NOT NULL,\n",
    "    key TEXT NOT NULL,\n",
    "    value TEXT NOT NULL,\n",
    "    type TEXT,\n",
    "    FOREIGN KEY (id) REFERENCES ways(id)\n",
    ");\n",
    "\n",
    "CREATE TABLE ways_nodes (\n",
    "    id INTEGER NOT NULL,\n",
    "    node_id INTEGER NOT NULL,\n",
    "    position INTEGER NOT NULL,\n",
    "    FOREIGN KEY (id) REFERENCES ways(id),\n",
    "    FOREIGN KEY (node_id) REFERENCES nodes(id)\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para importar nossos arquivos CSV para suas respectivas tabelas, é necessário executar as seguintes instruções no *shell* do SQLite:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ".separator \"|\"\n",
    ".import nodes.csv nodes\n",
    ".import ways.csv ways\n",
    ".import nodes_tags.csv nodes_tags\n",
    ".import ways_tags.csv ways_tags\n",
    ".import ways_nodes.csv ways_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os dados em JSON seguem o seguinte modelo de documento:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "{\n",
    "\"id\": \"2406124091\",\n",
    "\"type: \"node\",\n",
    "\"visible\":\"true\",\n",
    "\"created\": {\n",
    "          \"version\":\"2\",\n",
    "          \"changeset\":\"17206049\",\n",
    "          \"timestamp\":\"2013-08-03T16:43:42Z\",\n",
    "          \"user\":\"linuxUser16\",\n",
    "          \"uid\":\"1219059\"\n",
    "        },\n",
    "\"pos\": [41.9757030, -87.6921867],\n",
    "\"address\": {\n",
    "          \"housenumber\": \"5157\",\n",
    "          \"postcode\": \"60625\",\n",
    "          \"street\": \"North Lincoln Ave\"\n",
    "        },\n",
    "\"amenity\": \"restaurant\",\n",
    "\"cuisine\": \"mexican\",\n",
    "\"name\": \"La Cabana De Don Luis\",\n",
    "\"phone\": \"1 (773)-271-5176\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para importar nosso arquivo JSON para uma coleção no MongoDB, fui utilizada a seguinte instrução no *shell* do MongoDB:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mongoimport -db P3 -c osm --file brasilia_brazil.osm.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fase 03: Exploração dos dados\n",
    "\n",
    "Com os dados carregados nos bancos de dados, podemos iniciar a exploração."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**NÚMERO DE *NODES* **"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "SQLite: \n",
    "--> SELECT COUNT(*) FROM nodes;\n",
    "--> 469773\n",
    "\n",
    "MongoDB: \n",
    "--> db.osm.find({\"type\": \"node\"}).count()\n",
    "--> 469773"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NÚMERO DE *WAYS* **"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "SQLite: \n",
    "--> SELECT COUNT(*) FROM ways;\n",
    "--> 94443\n",
    "\n",
    "MongoDB: \n",
    "--> db.osm.find({\"type\":\"way\"}).count()\n",
    "--> 94443"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NÚMERO DE USUÁRIOS ÚNICOS**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "SQLite:\n",
    "--> SELECT COUNT(DISTINCT e.uid) FROM (SELECT uid FROM nodes UNION ALL SELECT uid FROM ways) e;\n",
    "--> 659\n",
    "\n",
    "MongoDB:\n",
    "--> db.osm.distinct('created.uid').length\n",
    "--> 659"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** TOP 10 CONTRIBUIDORES **"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "SQLite:\n",
    "--> SELECT \n",
    "-->  e.user\n",
    "--> ,COUNT(*) AS num \n",
    "--> FROM (SELECT user FROM nodes UNION ALL SELECT user FROM ways) e \n",
    "--> GROUP BY e.user \n",
    "--> ORDER BY num DESC\n",
    "--> LIMIT 10;\n",
    "\n",
    "erickdeoliveiraleal,130873\n",
    "Linhares,45897\n",
    "street0501,40582\n",
    "MAPconcierge,38129\n",
    "teste18,29037\n",
    "wille,18577\n",
    "Rusleykcruz,14687\n",
    "woodpeck_repair,13691\n",
    "jadson_reis,13070\n",
    "charliekowacks,12754\n",
    "\n",
    "MongoDB:\n",
    "--> db.osm.aggregate([\n",
    "-->   {\"$group\": {\"_id\": \"$created.user\"\n",
    "-->              ,\"count\": {\"$sum\": 1}}}\n",
    "-->  ,{\"$sort\": {\"count\": -1}}\n",
    "-->  ,{\"$limit\": 10}])\n",
    "\n",
    "{ \"_id\" : \"erickdeoliveiraleal\", \"count\" : 130873 }\n",
    "{ \"_id\" : \"Linhares\", \"count\" : 45897 }\n",
    "{ \"_id\" : \"street0501\", \"count\" : 40582 }\n",
    "{ \"_id\" : \"MAPconcierge\", \"count\" : 38129 }\n",
    "{ \"_id\" : \"teste18\", \"count\" : 29037 }\n",
    "{ \"_id\" : \"wille\", \"count\" : 18577 }\n",
    "{ \"_id\" : \"Rusleykcruz\", \"count\" : 14687 }\n",
    "{ \"_id\" : \"woodpeck_repair\", \"count\" : 13691 }\n",
    "{ \"_id\" : \"jadson_reis\", \"count\" : 13070 }\n",
    "{ \"_id\" : \"charliekowacks\", \"count\" : 12754 }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TOP 10 TIPOS DE LOCAIS**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "SQLite:\n",
    "--> SELECT \n",
    "-->  v.value\n",
    "--> ,SUM(v.count) as count\n",
    "--> FROM\n",
    "--> (SELECT value as value ,1 as count FROM nodes_tags WHERE key='amenity'\n",
    "-->  UNION ALL\n",
    "-->  SELECT value as value ,1 as count FROM ways_tags WHERE key='amenity') v\n",
    "--> GROUP BY value \n",
    "--> ORDER BY count DESC \n",
    "--> LIMIT 10;\n",
    "\n",
    "parking,1184\n",
    "school,937\n",
    "restaurant,756\n",
    "place_of_worship,406\n",
    "fuel,352\n",
    "fast_food,345\n",
    "bar,263\n",
    "pharmacy,241\n",
    "bank,215\n",
    "police,201\n",
    "\n",
    "MongoDB:\n",
    "--> db.osm.aggregate([{\"$match\": {\"amenity\": {\"$exists\": 1}}}\n",
    "-->                  ,{\"$group\": {\"_id\": \"$amenity\"\n",
    "-->                              ,\"count\": {\"$sum\": 1}}}\n",
    "-->                  ,{\"$sort\": {\"count\": -1}}\n",
    "-->                  ,{\"$limit\": 10}])\n",
    "\n",
    "{ \"_id\" : \"parking\", \"count\" : 1184 }\n",
    "{ \"_id\" : \"school\", \"count\" : 937 }\n",
    "{ \"_id\" : \"restaurant\", \"count\" : 756 }\n",
    "{ \"_id\" : \"place_of_worship\", \"count\" : 406 }\n",
    "{ \"_id\" : \"fuel\", \"count\" : 352 }\n",
    "{ \"_id\" : \"fast_food\", \"count\" : 345 }\n",
    "{ \"_id\" : \"bar\", \"count\" : 263 }\n",
    "{ \"_id\" : \"pharmacy\", \"count\" : 241 }\n",
    "{ \"_id\" : \"bank\", \"count\" : 215 }\n",
    "{ \"_id\" : \"police\", \"count\" : 201 }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PRINCIPAL TIPO DE RESTAURANTE**\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "SQLite:\n",
    "--> SELECT\n",
    "-->   nt.value\n",
    "-->  ,COUNT(*) as num\n",
    "--> FROM nodes_tags nt\n",
    "--> JOIN (SELECT DISTINCT(id) FROM nodes_tags WHERE value='restaurant') i\n",
    "-->   ON nt.id=i.id\n",
    "--> WHERE nt.key='cuisine'\n",
    "--> GROUP BY nt.value\n",
    "--> ORDER BY num DESC\n",
    "--> LIMIT 1;\n",
    "\n",
    "pizza,98\n",
    "\n",
    "MongoDB:\n",
    "--> db.osm.aggregate([{\"$match\": {\"type\": \"node\"\n",
    "                                 ,\"amenity\": {\"$exists\": 1}\n",
    "                                 ,\"cuisine\": {\"$exists\": 1}\n",
    "                                 ,\"amenity\": \"restaurant\"}}\n",
    "                     ,{\"$group\": {\"_id\": \"$cuisine\"\n",
    "                                 ,\"count\": {\"$sum\": 1}}}\n",
    "                     ,{\"$sort\": {\"count\": -1}}\n",
    "                     ,{\"$limit\": 1}])\n",
    "                     \n",
    "{ \"_id\" : \"pizza\", \"count\" : 98 }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUADRA COM MAIOR QUANTIDADE DE BARES**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "SQLite:\n",
    "--> SELECT \n",
    "-->   nd1.value AS addr\n",
    "-->  ,COUNT(nd1.id) AS qtd \n",
    "--> FROM nodes_tags nd1 \n",
    "--> WHERE nd1.type LIKE '%addr%' \n",
    "-->   AND (nd1.value LIKE '%CLN%' OR nd1.value LIKE '%CLS%') \n",
    "-->   AND nd1.id IN (\n",
    "-->       SELECT id \n",
    "-->       FROM nodes_tags \n",
    "-->       WHERE key = 'amenity' \n",
    "-->         AND value = 'bar' \n",
    "-->       UNION \n",
    "-->       SELECT id \n",
    "-->       FROM ways_tags \n",
    "-->       WHERE key = 'amenity' \n",
    "-->         AND value = 'bar')\n",
    "--> GROUP BY nd1.value\n",
    "--> ORDER BY 2 DESC \n",
    "--> LIMIT 1;\n",
    "\n",
    "Comércio Local Norte (CLN) 408,6\n",
    "\n",
    "MongoDB:\n",
    "--> db.osm.aggregate([\n",
    "        {\"$match\": {\n",
    "            \"address.street\": {\n",
    "                \"$exists\": 1\n",
    "               ,\"$regex\": /.*CLN|CLS.*/}\n",
    "           ,\"amenity\": {\n",
    "                \"$exists\": 1\n",
    "               ,\"$regex\": /^bar$/}}}\n",
    "       ,{\"$group\": {\n",
    "            \"_id\": \"$address.street\"\n",
    "           ,\"count\": {\"$sum\": 1}}}\n",
    "       ,{\"$limit\": 1}])\n",
    "                     \n",
    "{ \"_id\" : \"Comércio Local Norte (CLN) 408\", \"count\" : 6 }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PIZZARIAS NAS PROXIMIDADES DA MINHA QUADRA**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "$MongoDB:\n",
    "--> db.osm.createIndex({\"pos\": \"2dsphere\"})\n",
    "--> db.osm.find({\"type\": \"node\"\n",
    "                ,\"amenity\": {\"$exists\": 1}\n",
    "                ,\"cuisine\": {\"$exists\": 1}\n",
    "                ,\"cuisine\": \"pizza\" \n",
    "                ,\"pos\": {$nearSphere: \n",
    "                          { $geometry: { type: \"Point\"\n",
    "                                       , coordinates: [-47.8933383,-15.7451663] }\n",
    "                          , $maxDistance: 1000 }}})\n",
    "                          \n",
    "{ \"_id\" : ObjectId(\"58d1cfa712fc241fa6d6c912\")\n",
    ", \"cuisine\" : \"pizza\"\n",
    ", \"amenity\" : \"restaurant\"\n",
    ", \"name\" : \"La Fornicella\"\n",
    ", \"created\" : { \"changeset\" : \"44934285\"\n",
    "              , \"user\" : \"wille\"\n",
    "              , \"version\" : \"2\"\n",
    "              , \"uid\" : \"360183\"\n",
    "              , \"timestamp\" : \"2017-01-05T19:53:48Z\" }\n",
    ", \"pos\" : [ -47.8926383, -15.750439 ]\n",
    ", \"type\" : \"node\"\n",
    ", \"id\" : \"3200842313\" }\n",
    "\n",
    "{ \"_id\" : ObjectId(\"58d1cfa612fc241fa6d5a2cc\")\n",
    ", \"cuisine\" : \"pizza\"\n",
    ", \"amenity\" : \"restaurant\"\n",
    ", \"name\" : \"Valentina\"\n",
    ", \"created\" : { \"changeset\" : \"20793373\"\n",
    "              , \"user\" : \"erickdeoliveiraleal\"\n",
    "              , \"version\" : \"1\"\n",
    "              , \"uid\" : \"463504\"\n",
    "              , \"timestamp\" : \"2014-02-26T16:06:12Z\" }\n",
    ", \"pos\" : [ -47.8875238, -15.745009 ]\n",
    ", \"phone\" : \"3340-6868\"\n",
    ", \"address\" : { \"street\" : \"Comércio Local Norte (CLN) 214 BL A LJ 9 11\"\n",
    "              , \"place\" : \"Asa Norte\" }\n",
    ", \"type\" : \"node\"\n",
    ", \"id\" : \"2691239630\" }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IDEIAS ADICIONAIS\n",
    "\n",
    "O projeto do Open Street Maps é, por si só, uma iniciativa sensacional, mas basta dar uma olhada nos dados e nos blogs/diários dos editores para entender o quão difícil é manter dados de qualidade quando qualquer um pode editá-los. Talvez a possibilidade de criar e ingressar em grupos de interesse do Open Street Maps possa facilitar a comunicação de usuários e/ou entidades que querem editar um local em comum.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CONCLUSÃO\n",
    "\n",
    "Após a exploração e análise dos dados, fica claro que o mapa da área de Brasília está incompleto. A documentação, apesar de sugerir padrões, parece ser pouco utilizada pelos colaboradores. O pouco uso destes padrões acaba dificultando a auditoria dos dados. Como sugestão, o OpenStreetMap poderia investir na criação de uma interface mais amigável que guie os colaboradores no momento da inserção dos dados, ajudando a melhorar a qualidade dos dados fornecidos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### REFERÊNCIAS\n",
    "\n",
    "- https://docs.google.com/document/d/1F0Vs14oNEs2idFJR3C_OPxwS6L0HPliOii-QpbmrMo4/pub \n",
    "- https://gist.github.com/carlward/54ec1c91b62a5f911c42#file-sample_project-md\n",
    "\n",
    "- https://wiki.openstreetmap.org/wiki/OSM_XML\n",
    "- https://wiki.openstreetmap.org/wiki/Elements\n",
    "\n",
    "- https://docs.mongodb.com/manual/core/2dsphere/\n",
    "- https://docs.mongodb.com/manual/reference/operator/query/near/#op._S_near\n",
    "- https://docs.mongodb.com/manual/tutorial/geospatial-tutorial/\n",
    "\n",
    "- http://regexr.com/\n",
    "- https://www.codeschool.com/courses/breaking-the-ice-with-regular-expressions\n",
    "\n",
    "- https://mapzen.com/data/metro-extracts/metro/brasilia_brazil/\n",
    "- http://siglasbsb.alanmol.com.br/p/siglas.html\n",
    "\n",
    "- http://www.tutorialspoint.com/sqlite/index.htm \n",
    "- https://sqlite.org/lang.html \n",
    "- https://stackoverflow.com/questions/29577713/string-field-value-length-in-mongodb/29578020\n",
    "- https://stackoverflow.com/questions/18501064/mongodb-aggregation-counting-distinct-fields\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
